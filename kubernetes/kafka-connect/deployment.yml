apiVersion: apps/v1beta2 # for versions before 1.8.0 use apps/v1beta1
kind: Deployment
metadata:
  name: kafka-connect
spec:
  selector:
    matchLabels:
      app: kafka-connect
  replicas: 2 # tells deployment to run 2 pods matching the template
  template: # create pods using pod definition in this template
    metadata:
      labels:
        app: kafka-connect
    spec:
      containers:
      - name: kafka-connect
        image: 921942764047.dkr.ecr.us-east-1.amazonaws.com/kafka-connect:0.0.1-beta
        ports:
        - containerPort: 8083
        env:
        - name: "CONNECT_REST_ADVERTISED_HOST_NAME"
          value: $HOSTNAME
        - name: "CONNECT_BOOTSTRAP_SERVERS"
          value: "r0.kafka.rush-street-gaming.aws.confluent.cloud:9092,r0.kafka.rush-street-gaming.aws.confluent.cloud:9093,r0.kafka.rush-street-gaming.aws.confluent.cloud:9094"
        - name: CONNECT_SASL_JAAS_CONFIG
          valueFrom:
            secretKeyRef:
              name: kafka-connect-bootstrap
              key: connect-sasl-jaas-config
        - name: "CONNECT_SECURITY_PROTOCOL"
          value: "SASL_SSL"
        - name: "CONNECT_SASL_MECHANISM"
          value: "PLAIN"
        - name: "CONNECT_PRODUCER_SASL_JAAS_CONFIG"
          valueFrom:
            secretKeyRef:
              name: kafka-connect-bootstrap
              key: connect-producer-sasl-jaas-config
        - name: "CONNECT_PRODUCER_SECURITY_PROTOCOL"
          value: "SASL_SSL"
        - name: "CONNECT_PRODUCER_SASL_MECHANISM"
          value: "PLAIN"
        - name: "CONNECT_REST_PORT"
          value: "8083"
        - name: "CONNECT_GROUP_ID"
          value: "connect-group-1"
        - name: "CONNECT_CONFIG_STORAGE_TOPIC"
          value: "connect-configs-2"
        - name: "CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR"
          value: "3"
        - name: "CONNECT_OFFSET_FLUSH_INTERVAL_MS"
          value: "10000"
        - name: "CONNECT_OFFSET_FLUSH_TIMEOUT_MS"
          value: "60000"
        - name: "CONNECT_OFFSET_STORAGE_TOPIC"
          value: "connect-offsets"
        - name: "CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR"
          value: "3"
        - name: "CONNECT_STATUS_STORAGE_TOPIC"
          value: "connect-status"
        - name: "CONNECT_STATUS_STORAGE_REPLICATION_FACTOR"
          value: "3"
        - name: "CONNECT_KEY_CONVERTER"
          value: "io.confluent.connect.avro.AvroConverter"
        - name: "CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL"
          value: "http://schemaregistry:8081"
        - name: "CONNECT_VALUE_CONVERTER"
          value: "io.confluent.connect.avro.AvroConverter"
        - name: "CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL"
          value: "http://schemaregistry:8081"
        - name: "CONNECT_INTERNAL_KEY_CONVERTER"
          value: "org.apache.kafka.connect.json.JsonConverter"
        - name: "CONNECT_INTERNAL_VALUE_CONVERTER"
          value: "org.apache.kafka.connect.json.JsonConverter"
        - name: "CONNECT_PLUGIN_PATH"
          value: "/usr/share/java"
        - name: "CONNECT_BUFFER_MEMORY"
          value: "50000"
      "imagePullSecrets": [
        {
          "name": "ecr-credentials"
        }
      ]

---
kind: ConfigMap
apiVersion: v1
metadata:
  name: kafka-connect-bootstrap
  namespace: default
data:
  payload.property.file: |-
    {
      \"name\":\"pipelines-prod-mysql-jdbc\",
      \"config\":{
        \"table.whitelist\":[\"tasks\",\"sources\"],
        \"connector.class\":\"io.confluent.connect.jdbc.JdbcSourceConnector\",
        \"tasks.max\":5,
        \"connection.url\":\"jdbc:mysql://pipelines-prod.cfgxykl7ettn.us-east-1.rds.amazonaws.com:3306/data_api_dev?user=$DB_PIPELINES_USERNAME\&password=$DB_PIPELINES_PASSWORD\",
        \"mode\":\"incrementing\",
        \"incrementing.column.name\":\"id\",
        \"topic.prefix\":\"pipelines-prod-\"
      }
    }
  script.property.file: |-
    #!/bin/bash
    payload=$(eval "echo "$(cat /opt/payload/payload.property.file)"")
    curl -X POST -H "Content-Type: application/json" --data "$(echo $payload)" http://kafka-connect:8083/connectors
