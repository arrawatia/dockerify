#!/usr/bin/env python

from __future__ import print_function

import os
import sys
import socket
import time
from contextlib import closing
import collections
import time
from kazoo.client import KazooClient
import json
import re
import requests

ZookeeperServer = collections.namedtuple('ZookeeperServer', 'host port')
KafkaServer = collections.namedtuple('KafkaServer', 'id host port endpoints')
KafkaEndpoint = collections.namedtuple('KafkaEndpoint', 'id protocol host port')
ZOOKEEPER_STAT_SOCKET_BUFFER = 20480


def wait_for_service(host, port, timeout):
    start = time.time()
    while True:
        try:
            s = socket.create_connection((host, int(port)), float(timeout))
            s.close()
            return True
        except socket.error:
            pass

        time.sleep(1)
        if time.time() - start > timeout:
            return False


def get_zk_mode(server):
    MODE_PREFIX = 'Mode: '
    try:
        lines = get_zk_stat(server).split("\n")
        for line in lines:
            if line.startswith(MODE_PREFIX):
                return line[len(MODE_PREFIX):]
    except socket.error:
        return 'down'
    return 'not serving'


def get_zk_stat(server):
    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
        s.connect(server)
        s.send('stat')
        data = s.recv(ZOOKEEPER_STAT_SOCKET_BUFFER)
    return data


def check_zk_ensemble_ready(modes):
    if "not serving" in modes or "down" in modes:
        return False

    if len(modes) == 1:
        return modes[0] == "standalone"
    else:
        # There should be only one leader and rest should be followers
        return modes.count("leader") == 1 and modes.count("follower") == len(modes) - 1


def parse_zk_connect_string(zk_connect_str):
    server_list = zk_connect_str.split("/")[0]
    servers = []
    for server in server_list.split(","):
        tokens = server.split(":")
        servers.append(ZookeeperServer(host=tokens[0], port=int(tokens[1])))
    return servers


def check_zookeeper_ready(zk_connect_str, service_timeout, ensemble_retries, ensemble_wait):
    servers = parse_zk_connect_string(zk_connect_str)

    # Wait for server to be up
    status = [wait_for_service(server.host, server.port, service_timeout) for server in servers]

    if all(status):
        for _ in xrange(ensemble_retries):
            modes = [get_zk_mode(server) for server in servers]
            if check_zk_ensemble_ready(modes):
                return True
            else:
                time.sleep(ensemble_wait)

        print("Ensemble in invalid state for [%s]" % zk_connect_str, file=sys.stderr)
        for i in xrange(len(servers)):
                print("%s = %s" % (str(servers[i]), modes[i]), file=sys.stderr)

        return False
    else:
        for i in xrange(len(servers)):
            if not status[i]:
                print("%s cannot be reached." % str(servers[i]), file=sys.stderr)
        return False


def parse_kafka_endpoints(broker_id, endpoints):

    parsed_endpoints = []
    for endpoint in endpoints:
        protocol_address = endpoint.split("://")
        host_port = protocol_address[1].split(":")
        parsed_endpoints.append(KafkaEndpoint(id=broker_id,
                                              protocol=protocol_address[0],
                                              host=host_port[0],
                                              port=host_port[1]))
    return parsed_endpoints


def get_brokers_in_zk(zk_connect, min_broker_count, cluster_retries, cluster_wait):
    brokers = []

    # This is required because chroot might not be created when we initiate the check.
    if "/" in zk_connect:
        tokens = zk_connect.split("/")
        chroot = "/".join([""] + tokens[1:])
        server = tokens[0]
    else:
        server = zk_connect
        chroot = "/"

    for i in xrange(cluster_retries):

        try:
            # Sleep between iterations. An iteration can fail if :
            # 1. ZK chroot not found
            # 2. Exception in communicating with ZK
            # 3. /brokers/ids znode is not created yet
            # 4. if count(/brokers/ids) < min_broker_count
            time.sleep(cluster_wait)
            zk = KazooClient(hosts=server, read_only=True)
            zk.start()

            # Check for chroot
            if zk.exists(chroot):
                zk.chroot = chroot
            else:
                continue

            # Check for brokers
            if zk.exists("/brokers/ids"):
                broker_ids = zk.get_children("/brokers/ids")

                brokers = []
                for i in broker_ids:
                    znode = zk.get("/brokers/ids/" + i)
                    broker = json.loads(znode[0])
                    brokers.append(KafkaServer(id=i,
                                               host=broker["host"],
                                               port=broker["port"],
                                               endpoints=parse_kafka_endpoints(i, broker["endpoints"])))
                if len(broker_ids) >= min_broker_count:
                    print("Brokers in ZK: %s" % brokers, file=sys.stderr)
                    return (len(broker_ids) >= min_broker_count, brokers)

        except Exception, e:
            print(e, file=sys.stderr)
        finally:
            zk.stop()

    return (False, brokers)


def check_kafka_ready(zk_connect, min_broker_count, service_timeout, cluster_retries, cluster_wait):
    min_brokers_found, brokers = get_brokers_in_zk(zk_connect, min_broker_count, cluster_retries, cluster_wait)
    if not min_brokers_found:
        print("Expected %s brokers but found %s. [%s] " % (min_broker_count, len(brokers), str(brokers)), file=sys.stderr)
        return False

    # Check if you can connect to the endpoints, they should be up and running at this point.
    endpoints = [endpoint for server in brokers for endpoint in server.endpoints]
    status = [wait_for_service(endpoint.host, endpoint.port, service_timeout) for endpoint in endpoints]

    if all(status):
        return True
    else:
        for i in xrange(len(endpoints)):
            if not status[i]:
                print("%s cannot be reached." % str(endpoints[i]), file=sys.stderr)
        return False


def check_schema_registry_ready(host, port, service_timeout):

    # Check if you can connect to the endpoint
    status = wait_for_service(host, port, service_timeout)

    if status:
        # Check if service is responding as expected to basic request
        url = "http://%s:%s/config" % (host, port)
        r = requests.get(url)
        # The call should always return the compatibilityLevel
        if r.status_code // 100 == 2 and 'compatibilityLevel' in str(r.text):
            return True
        else:
            print("Unexpected response with code: %s and content: %s" % (str(r.status_code),str(r.text)), file=sys.stderr)
            return False
    else:
        print("%s cannot be reached on port %s." % (str(host), str(port)), file=sys.stderr)
        return False


def check_kafka_rest_ready(host, port, service_timeout):

    # Check if you can connect to the endpoint
    status = wait_for_service(host, port, service_timeout)

    if status:

        # Check if service is responding as expected to basic request
        # Try to get topic list
        # NOTE: this will only test ZK <> REST Proxy interaction
        url = "http://%s:%s/topics" % (host, port)
        r = requests.get(url)
        if r.status_code // 100 == 2:
            return True
        else:
            print("Unexpected response with code: %s and content: %s" % (str(r.status_code),str(r.text)), file=sys.stderr)
            return False
    else:
        print("%s cannot be reached on port %s." % (str(host), str(port)), file=sys.stderr)
        return False


def get_kafka_listeners(advertised_listeners):
    host = re.compile(r'://(.*?):', re.UNICODE)
    return host.sub(r'://0.0.0.0:', advertised_listeners)


if __name__ == '__main__':

    import argparse
    root = argparse.ArgumentParser(description='Confluent Platform Utility Belt.')

    actions = root.add_subparsers(help='Actions', dest='action')

    zk = actions.add_parser('zk-ready', description='Check if ZK is ready.')
    zk.add_argument('connect_string', help='Zookeeper connect string.')
    zk.add_argument('timeout', help='Time in secs to wait for service to be ready.', type=int)
    zk.add_argument('retries', help='No of retries to check if leader election is complete.', type=int)
    zk.add_argument('wait', help='Time in secs between retries', type=int)

    kafka = actions.add_parser('kafka-ready', description='Check if Kafka is ready.')
    kafka.add_argument('connect_string', help='Zookeeper connect string.')
    kafka.add_argument('min_brokers', help='Minimum number of brokers to wait for', type=int)
    kafka.add_argument('timeout', help='Time in secs to wait for service to be ready.', type=int)
    kafka.add_argument('retries', help='No of retries to check if leader election is complete.', type=int)
    kafka.add_argument('wait', help='Time in secs between retries', type=int)

    sr = actions.add_parser('sr-ready', description='Check if Schema Registry is ready.')
    sr.add_argument('host', help='Hostname for Schema Registry.')
    sr.add_argument('port', help='Port for Schema Registry.')
    sr.add_argument('timeout', help='Time in secs to wait for service to be ready.', type=int)

    kr = actions.add_parser('kr-ready', description='Check if Kafka REST Proxy is ready.')
    kr.add_argument('host', help='Hostname for REST Proxy.')
    kr.add_argument('port', help='Port for REST Proxy.')
    kr.add_argument('timeout', help='Time in secs to wait for service to be ready.', type=int)

    config = actions.add_parser('listeners', description='Get listeners value from advertised.listeners. Replaces host to 0.0.0.0')
    config.add_argument('advertised_listeners', help='advertised.listeners string.')

    if len(sys.argv) < 2:
        root.print_help()
        sys.exit(1)

    args = root.parse_args()

    success = False

    if args.action == "zk-ready":
        success = check_zookeeper_ready(args.connect_string, int(args.timeout), int(args.retries), int(args.wait))
    elif args.action == "kafka-ready":
        success = check_kafka_ready(args.connect_string, int(args.min_brokers), int(args.timeout), int(args.retries), int(args.wait))
    elif args.action == "sr-ready":
        success = check_schema_registry_ready(args.host, args.port, int(args.timeout))
    elif args.action == "kr-ready":
        success = check_kafka_rest_ready(args.host, args.port, int(args.timeout))
    elif args.action == "listeners":
        listeners = get_kafka_listeners(args.advertised_listeners)
        if listeners:
            print(listeners)
            success = True

    if success:
        sys.exit(0)
    else:
        sys.exit(1)
